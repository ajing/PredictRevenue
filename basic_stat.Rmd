---
title: "basic_stat"
output: html_document
---

Cleaning and some basic operation on data
```{r}
train_data <- read.csv("./Data/train.csv")
test_data  <- read.csv("./Data/test.csv")
train_data$Open.Date = as.Date(train_data$Open.Date, "%m/%d/%Y")
test_data$Open.Date = as.Date(test_data$Open.Date, "%m/%d/%Y")
levels(train_data$Type) = levels(test_data$Type)
levels(train_data$City) = levels(test_data$City)
```

Basic statistics for each variable:
```{r}
summary(train_data)
summary(test_data)
```

boxplot for revenue and P1-P37
```{r}
boxplot(train_data$revenue)
boxplot(x = train_data[, grepl( "P+" , names(train_data))])
```

remove the outlier
```{r}
train_data = subset(train_data, revenue < 1e7)
```

PCA analysis
```{r}
train_pca <- prcomp(train_data[, grepl( "P+" , names(train_data))], center = TRUE, scale = TRUE) 
summary(train_pca)
plot(train_pca)
```

```{r}
biplot(train_pca,choices=c(1,2),cex=0.5, main = "Train data biplot")
PC=predict(train_pca)[,1:3]
summary(PC)
barplot(train_pca$rotation[,"PC1"])
barplot(train_pca$rotation[,"PC2"])
barplot(train_pca$rotation[,"PC3"])
```

```{r}
test_pca <- prcomp(test_data[, grepl( "P+" , names(test_data))], center = TRUE, scale = TRUE) 
summary(test_pca)
plot(test_pca)

biplot(test_pca,choices=c(1,2),cex=0.05, main = "Test data biplot")
PC=predict(test_pca)[,1:3]
summary(PC)
barplot(test_pca$rotation[,"PC1"])
barplot(test_pca$rotation[,"PC2"])
barplot(test_pca$rotation[,"PC3"])
```

Correlation between individuals
```{r, echo=FALSE}
library("gplots")
heatmap.2(as.matrix(train_data[, grepl( "P+" , names(train_data))]), scale="column")
```

```{r}
pairs(~P1+P2+P3+P4+P5+P6+P7+P8,data=train_data)
```

```{r}
PC1=predict(train_pca)[,1]
PC2=predict(train_pca)[,2]
PC3=predict(train_pca)[,3]
model <- lm(revenue ~ PC1 + PC2 + PC3,data = train_data)
summary(model)

model <- lm(revenue ~ P1 + P2 + P3 + P4 + P5 + P6 + P7 + P8 + P9 + P10 + P11 + P12 + P13 + P13 + P14 + P15 + P16 + P17 + P18 + P19 + P20 + P21 + P22 + P23 + P24 + P25 + P26,data = train_data)
summary(model)
```

```{r}
train_data_s = cbind(revenue = train_data[, "revenue"], train_data[, grepl( "P+" , names(train_data))])
model <- lm(revenue ~ .,data = train_data_s)
summary(model)
pre_result_train <- predict(model, train_data_s)
sqrt(sum((pre_result_train - train_data_s$revenue)^2))
pre_result <- predict(model, test_data)
```

SVM
```{r}
library('e1071')
obj <- tune.svm(revenue~., data = subset(train_data, select = -Id), gama = 2^(-10:1), cost = 2^(2:10))
model <- obj$best.model
pre_result_train <- predict(model, subset(train_data,select = Open.Date:P37))
sqrt(sum((pre_result_train - train_data$revenue)^2))
pre_result <- predict(model, subset(test_data, select = -Id))
```

randomForest
```{r}
library("randomForest")
model <- randomForest(revenue~.,data=subset(train_data, select = !(names(train_data) %in% c("Id", "City"))))
pre_result_train <- predict(model, subset(train_data,select = Open.Date:P37))
sqrt(sum((pre_result_train - train_data$revenue)^2))
pre_result <- predict(model, subset(test_data, select = -Id))
```

Save prediction to file
```{r}

write.csv(cbind(Id = test_data$Id, Prediction = pre_result), quote = F, row.names = F, file = "./predict_result.csv")
```
