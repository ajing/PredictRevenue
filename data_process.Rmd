---
title: "data_preprocess"
author: "ajing"
date: "04/19/2015"
output: html_document
---


Cleaning and some basic operation on data
```{r}
train_data <- read.csv("./Data/train.csv")
test_data  <- read.csv("./Data/test.csv")
train_data$Open.Date = as.numeric(as.Date(train_data$Open.Date, "%m/%d/%Y"))
test_data$Open.Date = as.numeric(as.Date(test_data$Open.Date, "%m/%d/%Y"))
levels(train_data$Type) = levels(test_data$Type)
levels(train_data$City) = levels(test_data$City)
#remove the outlier
train_data = subset(train_data, revenue < 1e7)
#remove Id and City
train_data <- subset(train_data, select = !(names(train_data) %in% c("Id")))
```

Only keep first 5 PCA (sd > 1)
```{r}
train_pca <- prcomp(train_data[, grepl( "P+" , names(train_data))], center = TRUE, scale = TRUE)
train_lowdim= cbind(train_data[, !grepl( "P+" , names(train_data))], predict(train_pca)[,1:5])
```

Testing set dimension reduction
```{r}
test_lowdim = cbind(test_data[, !grepl( "P+" , names(test_data))], predict(train_pca, newdata = test_data[, grepl( "P+" , names(test_data))])[,1:5])
```

Preprocess
```{r}
pre_pro <- function(myData){
  #Consolidate Cities
  all_cities <-
  myData$City                                      <- as.character(myData$City)
  myData$City[myData$City.Group == "Other"]        <- "Other"
  myData$City[myData$City == unique(myData$City)[4]] <- unique(myData$City)[2]
  myData$City                                      <- factor(myData$City, levels = c("Diyarbakır", "Ankara", "İstanbul", "Other"))
  myData$City.Group                                <- NULL

  #Consolidate Types
  myData$Type <- as.character(myData$Type)
  myData$Type[myData$Type=="DT"] <- "IL"
  myData$Type[myData$Type=="MB"] <- "FC"
  myData$Type <- as.factor(myData$Type)
  # log transform
  #myData[, paste("P", 1:37, sep="")] <- log(1 +myData[, paste("P", 1:37, sep="")])
  #if("revenue" %in% names(myData)) {
  #  myData$revenue <- log(myData$revenue)
  #}
  myData
}
train_data <- pre_pro(train_data)
test_data <- pre_pro(test_data)

train_lowdim <- pre_pro(train_lowdim)
test_lowdim  <- pre_pro(test_lowdim)
```


Feature selection with Boruta
```{r}
library(Boruta)
important <- Boruta(revenue~., data=subset(train_data, select = !(names(train_data) %in% c("Id", "City"))))
names(train_data[, c(important$finalDecision != "Rejected", T)])
```

Simple RF
```{r}
library(randomForest)
model <- randomForest(revenue~.,data=train_data[, c(important$finalDecision != "Rejected", T)], importance = T, ntree = 200, maxnodes = 20)
#model <- randomForest(revenue~.,data=subset(train_data, select = !(names(train_data) %in% c("Id", "City"))), importance = T, ntree = 200, maxnodes = 20)
pre_result_train <- predict(model, train_data)
sqrt(sum((pre_result_train - train_data$revenue)^2)/ length(train_data$revenue))
#sqrt(sum((exp(pre_result_train) - exp(train_data$revenue))^2)/ length(train_data$revenue))
pre_result <- predict(model, subset(test_data, select = -Id))
```


SVM with feature selection
```{r}

```

Imputation
```{r}

```

How to fix the output distribution?
```{r}
library(ggplot2)
revenue_data <- rbind(merge(train_data$revenue, "orig"), merge(pre_result_train, "pred"), merge(pre_result, "pred_t"))
colnames(revenue_data) <- c("revenue", "type")
ggplot(revenue_data, aes(x = revenue, color = type)) + geom_density()
```

Transform one empirical distribution to another empirical distribution
```{r}
transformdist <- function(data1, data2){
  # transform from ecdf of data1 to data2
  data1_ecdf <- ecdf(data1)
  per_data1  <- data1_ecdf(data1)
  as.vector(quantile(data2, per_data1))
}
transformdist(train_data$revenue, pre_result_train)
```

Fit to log normal distribution
```{r}
library(fitdistrplus)
rev_dist = fitdist(train_data$revenue, "lnorm")
plot(rev_dist)
```


Simple RF
```{r}
model <- randomForest(revenue~.,data=train_data[, c(important$finalDecision != "Rejected", T)], importance = T, ntree = 200, maxnodes = 20)
model <- randomForest(revenue~.,data=subset(train_data, select = !(names(train_data) %in% c("Id", "City"))), importance = T, ntree = 200, maxnodes = 20)
pre_result_train <- predict(model, train_data)
plot(pre_result_train, train_data$revenue, col = c("red", "blue")[1 + (train_data$City.Group == "Other")])
abline(0,1)
sqrt(sum((pre_result_train - train_data$revenue)^2)/ length(train_data$revenue))
sqrt(sum((exp(pre_result_train) - exp(train_data$revenue))^2)/ length(train_data$revenue))

pre_result <- transformdist(predict(model, subset(test_data, select = -Id)),train_data$revenue)
```

Simple SVM
```{r}
library('e1071')
obj <- tune.svm(revenue~., data = train_data[, c(important$finalDecision != "Rejected", T)], gama = 2^(-10:1), cost = 2^(2:10))
model <- obj$best.model
pre_result_train <- predict(model, subset(train_data,select = Open.Date:P37))
sqrt(sum((pre_result_train - train_data$revenue)^2))
pre_result <- predict(model, subset(test_data, select = -Id))
```

Save prediction to file
```{r}
write.csv(cbind(Id = test_data$Id, Prediction = pre_result), quote = F, row.names = F, file = "./predict_result.csv")
```

ggplot distribution with real revenue
```{r}
library(ggplot2)
plot_dist <- function(predict_v) {
  combined <- rbind(data.frame(type = "predict", value = predict_v), data.frame(type = "real", value = train_data$revenue))
  ggplot(combined, aes(x = value, color = type)) + geom_density()
}
plot_dist(pre_result_train)

plot_dist(as.vector(quantile(train_data$revenue, pre_result_train)))

```
